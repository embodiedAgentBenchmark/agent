<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Embodied Agent in Urban Environment">
  <meta name="keywords" content="Embodied, Embodied,Benchmark, Agent, GPT-4V">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Embodied Agent in Urban Environment</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=??"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', '???');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Embodied Agent in Urban Environment</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">

<!--                <span class="author-block">-->
<!--                  <span>Author : </span>-->
<!--              </span>-->
<!--              <a href="https://fi.ee.tsinghua.edu.cn/~gaochen/">Chen Gao et al.</a><sup>*</sup>-->
<!--              </span>-->

<!--          </div>-->

<!--          <div class="is-size-5 publication-authors">-->
<!--            <span class="author-block">Tsinghua University&nbsp;&nbsp;</span>-->
<!--            <span class="author-block">&nbsp;Beijing, China</span>-->
<!--          </div>-->

<!--           <div class="is-size-5 publication-authors">-->
<!--                <span class="author-block"><sup>*</sup> Equal contribution </span>-->
<!--                <span class="author-block"><sup>&sect;</sup> Corresponding authors</span>-->
<!--           </div>-->
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
              <strong>Embodied intelligence</STRONG> is considered one of the possible approaches toward artificial general intelligence (AGI), which focuses on the ability to perceive first-view data from the world and make decisions adaptively based on the feedback received. We first <strong>review</strong> advances in LLM agent-based embodied intelligence and provide resources and future directions for research and development.
           </p>
            <p>
               Then, we propose a comprehensive benchmark <strong>platform</strong> and agents powered by large pre-trained models in complex urban environment. This platform includes a simulator and datasets for evaluating five representative tasks of embodied intelligence in urban environments, focusing on scene understanding, reasoning, and decision-making.
            </p>
          <p>
            Within this benchmark, we delve into two <strong>critical embodied tasks</strong>. The first task is vision-and-
              language navigation (VLN), where an agent navigates following human language instructions.
              Traditional VLN agents, which perform well in indoor environments using navigation graphs, struggle
              in 3D continuous urban spaces. To address this, we introduce <strong>CityNav</strong>, a <strong>city-level VLN</strong> agent that employs semantic map-based spatial reasoning and a topological memory graph for robust navigation in urban environments. CityNav constructs a 3D local semantic map, utilizes LLMs for common-sense reasoning, and records navigable locations in a memory graph, significantly enhancing navigation performance.
          </p>
          <p>
              The second key task is <strong>location-goal embodied navigation</strong>, particularly relevant to drone delivery
              systems in urban settings. We present <strong>DeliverGPT</strong>, an agent powered by large pre-trained models, featuring modules for perception, planning, motion, and memory. DeliverGPT builds a semantic graph for spatial understanding and uses a memory mechanism to improve delivery efficiency. Experimental results demonstrate a substantial performance improvement over existing methods, showcasing the effectiveness of integrating semantic graphs and memory mechanisms in drone-based navigation tasks.
          </p>

        </div>
      </div>
    </div>
</section>


<section class="section">
    <div class="container is-max-desktop">
        <div class="columns is-centered">
            <div class="column is-full-width">

                <h2 class="title is-3" >Benchmark</h2>

                    <br></br>
                <h3 class="title is-4" >Author</h3>
                <p>
                    Chen Gao
, Baining Zhao
, Weichen Zhang, Jinzhu Mao,
Fanhang Man, Jianjie Fang, Zile Zhou, Jinqiang Cui,
Xinlei Chen, Yong Li
                    <br></br>
                </p>
                    <h3 class="title is-4" >Introduction</h3>
                    <div class="content has-text-justified">

                    <p>
                        We first constructed a city-embodied environment simulator. This platform is developed based on a city simulator, providing 3D environments and interactions. The basic environment of the simulator includes a large business district in Beijing, one of the biggest city in China, in which we build 3D model for buildings, streets, and other elements, hosted by Unreal Engine 4.17. We further build the interface of embodied agents to ensure the agents can indeed embod themselves in the system. To implement it,we use the AirSim plugin provide by Microsoft. Specifically, AirSim is originally designed for airdrones, for which the observations are conducted through a first-view manner, and the control for airdrones includes motion, velocity, accelerated velocity, etc.
                    </p>

                    <h3 class="title is-5" style="text-align: center;">Benchmark Framework</h3>
                    <img src="./static/images/figure1.jpg" alt="Figure 1" style="width: 80%; height: auto; display: block; margin: 0 auto;">

                    <h3 class="title is-5" style="text-align: center;">Overview of Simulator</h3>
                    <img src="./static/images/simulator.jpg"/>

                    <p>
                       We defined a system of five tasks, including embodied scene description, embodied question answering, embodied dialogue, embodied visual language navigation, and embodied task planning. For each task, we carefully and manually set up the input/output, and construct the ground truth data combined with large language models and human labor. We also provide the interface for the platform through which the agents can obtain the embodied observations and take actions in real-time simulation, after which the agent can be evaluated. Moreover, we deploy the most famous and widely used large language models to construct the embodied agents, the intelligence level of which is evaluated on five tasks.
                    </p>

                    <h3 class="title is-5" style="text-align: center;">Embodied Tasks</h3>
                    <img src="./static/images/benchmark.jpg"/>
    </div>
</section>


<section class="section">
    <div class="container is-max-desktop">
        <div class="columns is-centered">
            <div class="column is-full-width">
                <h3 class="title is-4" >Result</h3>
                <div class="content has-text-justified">

                    <br><br>
                    <table>
                        <p>Table 1 :Results of embodied first-view scene understanding, including typical evaluation metrics: BLEU, ROUGE, METEOR, and CIDEr.</p>
                        <tr>
                            <th>Model</th>
                            <th>BLEU-1</th>
                            <th>BLEU-2</th>
                            <th>BLEU-3</th>
                            <th>BLEU-4</th>
                            <th>ROUGE</th>
                            <th>METEOR</th>
                            <th>CIDEr</th>
                        </tr>
                        <tr>
                            <td>fuyu-8B</td>
                            <td>40.25</td>
                            <td>20.26</td>
                            <td>8.40</td>
                            <td>1.57</td>
                            <td>17.29</td>
                            <td>15.80</td>
                            <td>21.55</td>
                        </tr>
                        <tr>
                            <td>Qwen-VL</td>
                            <td>40.57</td>
                            <td>17.59</td>
                            <td>5.90</td>
                            <td>0.98</td>
                            <td>14.61</td>
                            <td>19.13</td>
                            <td>18.40</td>
                        </tr>
                        <tr>
                            <td>Claude 3</td>
                            <td>57.38</td>
                            <td>31.73</td>
                            <td>16.83</td>
                            <td>7.19</td>
                            <td>21.60</td>
                            <td>29.00</td>
                            <td>29.20</td>
                        </tr>
                        <tr>
                            <td>GPT-4 Turbo</td>
                            <td>54.01</td>
                            <td>27.63</td>
                            <td>12.73</td>
                            <td>4.53</td>
                            <td>21.99</td>
                            <td>28.48</td>
                            <td>22.39</td>
                        </tr>
                    </table>

                    <br><br>
                    <table>
                        <p>Table 2 :Results of embodied question answering. The Counting task involves querying the number
                            of a specific object within the field of view. The Property task entails inquiring about the attributes of
                            spatial entities such as city buildings or objects within the field of view, including aspects like shape
                            and color. The Position task concerns querying the spatial relationships between different urban
                            elements within the field of view.
                        </p>

                        <tr>
                            <th>Type</th>
                            <th>Model</th>
                            <th>BLEU-1</th>
                            <th>BLEU-2</th>
                            <th>BLEU-3</th>
                            <th>BLEU-4</th>
                            <th>ROUGE</th>
                            <th>METEOR</th>
                            <th>CIDEr</th>
                        </tr>
                        <tr>
                            <td rowspan="4">Counting</td>
                            <td>fuyu-8B</td>
                            <td>12.00</td>
                            <td>7.15</td>
                            <td>1.07</td>
                            <td>0.40</td>
                            <td>16.45</td>
                            <td>15.41</td>
                            <td>8.87</td>
                        </tr>
                        <tr>
                            <td>Qwen-VL</td>
                            <td>5.49</td>
                            <td>1.19</td>
                            <td>0.10</td>
                            <td>0.00</td>
                            <td>11.46</td>
                            <td>17.89</td>
                            <td>3.58</td>
                        </tr>
                        <tr>
                            <td>Claude 3</td>
                            <td>6.08</td>
                            <td>4.33</td>
                            <td>2.79</td>
                            <td>2.13</td>
                            <td>10.54</td>
                            <td>16.82</td>
                            <td>7.95</td>
                        </tr>
                        <tr>
                            <td>GPT-4 Turbo</td>
                            <td>12.84</td>
                            <td>8.81</td>
                            <td>4.33</td>
                            <td>2.78</td>
                            <td>19.26</td>
                            <td>20.18</td>
                            <td>11.56</td>
                        </tr>
                        <tr>
                            <td rowspan="4">Property</td>
                            <td>fuyu-8B</td>
                            <td>20.19</td>
                            <td>18.36</td>
                            <td>16.39</td>
                            <td>14.64</td>
                            <td>31.55</td>
                            <td>20.34</td>
                            <td>22.56</td>
                        </tr>
                        <tr>
                            <td>Qwen-VL</td>
                            <td>55.77</td>
                            <td>48.43</td>
                            <td>40.90</td>
                            <td>31.94</td>
                            <td>65.33</td>
                            <td>61.73</td>
                            <td>33.30</td>
                        </tr>
                        <tr>
                            <td>Claude 3</td>
                            <td>49.34</td>
                            <td>41.88</td>
                            <td>34.10</td>
                            <td>23.44</td>
                            <td>60.51</td>
                            <td>55.29</td>
                            <td>29.84</td>
                        </tr>
                        <tr>
                            <td>GPT-4 Turbo</td>
                            <td>76.63</td>
                            <td>72.17</td>
                            <td>68.57</td>
                            <td>65.51</td>
                            <td>80.16</td>
                            <td>77.10</td>
                            <td>61.44</td>
                        </tr>
                        <tr>
                            <td rowspan="4">Position</td>
                            <td>fuyu-8B</td>
                            <td>7.46</td>
                            <td>0.15</td>
                            <td>0.00</td>
                            <td>0.00</td>
                            <td>18.94</td>
                            <td>4.40</td>
                            <td>12.86</td>
                        </tr>
                        <tr>
                            <td>Qwen-VL</td>
                            <td>7.88</td>
                            <td>4.63</td>
                            <td>3.81</td>
                            <td>0.83</td>
                            <td>18.03</td>
                            <td>22.00</td>
                            <td>16.62</td>
                        </tr>
                        <tr>
                            <td>Claude 3</td>
                            <td>7.57</td>
                            <td>5.85</td>
                            <td>4.37</td>
                            <td>1.56</td>
                            <td>19.04</td>
                            <td>34.28</td>
                            <td>18.82</td>
                        </tr>
                        <tr>
                            <td>GPT-4 Turbo</td>
                            <td>64.54</td>
                            <td>61.85</td>
                            <td>59.44</td>
                            <td>55.31</td>
                            <td>70.72</td>
                            <td>68.87</td>
                            <td>58.45</td>
                        </tr>
                    </table>



                    <br><br>
                    <table>
                        <caption>Table 3 :Results of embodied dialogue.</caption>
                        <tr>
                            <th>Model</th>
                            <th>BLEU-1</th>
                            <th>BLEU-2</th>
                            <th>BLEU-3</th>
                            <th>BLEU-4</th>
                            <th>ROUGE</th>
                            <th>METEOR</th>
                            <th>CIDEr</th>
                        </tr>
                        <tr>
                            <td>fuyu-8B</td>
                            <td>29.05</td>
                            <td>16.73</td>
                            <td>8.24</td>
                            <td>4.30</td>
                            <td>28.53</td>
                            <td>30.12</td>
                            <td>14.47</td>
                        </tr>
                        <tr>
                            <td>Qwen-VL</td>
                            <td>17.91</td>
                            <td>9.54</td>
                            <td>3.90</td>
                            <td>2.03</td>
                            <td>19.33</td>
                            <td>19.65</td>
                            <td>10.30</td>
                        </tr>
                        <tr>
                            <td>Claude 3</td>
                            <td>24.86</td>
                            <td>18.02</td>
                            <td>13.14</td>
                            <td>9.70</td>
                            <td>29.06</td>
                            <td>38.56</td>
                            <td>28.62</td>
                        </tr>
                        <tr>
                            <td>GPT-4 Turbo</td>
                            <td>41.77</td>
                            <td>34.27</td>
                            <td>27.82</td>
                            <td>23.26</td>
                            <td>42.29</td>
                            <td>51.72</td>
                            <td>35.64</td>
                        </tr>
                    </table>


                    <br><br>
                    <table>
                      <caption>Table 4: Results of embodied vision-and-language navigation.</caption>
                      <thead>
                         <tr>
                          <th rowspan="2" style="vertical-align: middle; text-align: center;">Model</th>
                          <th colspan="3" style="vertical-align: middle; text-align: center;">Short</th>
                          <th colspan="3" style="vertical-align: middle; text-align: center;">Long</th>
                          <th colspan="3" style="vertical-align: middle; text-align: center;">Mean</th>
                        </tr>
                        <tr>
                          <th>SR/%</th>
                          <th>SPL/%</th>
                          <th>NE/m</th>
                          <th>SR/%</th>
                          <th>SPL/%</th>
                          <th>NE/m</th>
                          <th>SR/%</th>
                          <th>SPL/%</th>
                          <th>NE/m</th>
                        </tr>
                      </thead>
                      <tbody>
                        <tr>
                          <td>Qwen-VL</td>
                          <td>33.33</td>
                          <td>29.60</td>
                          <td>67.30</td>
                          <td>8.33</td>
                          <td>6.67</td>
                          <td>145.3</td>
                          <td>22.22</td>
                          <td>19.33</td>
                          <td>120.44</td>
                        </tr>
                        <tr>
                          <td>Claude 3</td>
                          <td>76.92</td>
                          <td>75.60</td>
                          <td>139.11</td>
                          <td>20.00</td>
                          <td>19.65</td>
                          <td>185.48</td>
                          <td>34.90</td>
                          <td>34.25</td>
                          <td>162.35</td>
                        </tr>
                        <tr>
                          <td>GPT-4 Turbo</td>
                          <td>60.90</td>
                          <td>55.21</td>
                          <td>95.93</td>
                          <td>15.62</td>
                          <td>14.16</td>
                          <td>127.87</td>
                          <td>27.71</td>
                          <td>25.12</td>
                          <td>111.92</td>
                        </tr>
                        <tr>
                          <td>GPT-4O</td>
                          <td>76.92</td>
                          <td>75.60</td>
                          <td>77.23</td>
                          <td>20.00</td>
                          <td>19.65</td>
                          <td>102.98</td>
                          <td>34.90</td>
                          <td>34.25</td>
                          <td>90.11</td>
                        </tr>
                      </tbody>
                    </table>

                    <br><br>
                    <table>
                        <caption>Table 5 :Results of embodied task planning.</caption>
                        <tr>
                            <th>Model</th>
                            <th>BLEU-1</th>
                            <th>BLEU-2</th>
                            <th>BLEU-3</th>
                            <th>BLEU-4</th>
                            <th>ROUGE</th>
                            <th>METEOR</th>
                            <th>CIDEr</th>
                        </tr>
                        <tr>
                            <td>fuyu-8B</td>
                            <td>15.11</td>
                            <td>6.37</td>
                            <td>1.71</td>
                            <td>0.45</td>
                            <td>14.72</td>
                            <td>19.11</td>
                            <td>16.84</td>
                        </tr>
                        <tr>
                            <td>Qwen-VL</td>
                            <td>20.28</td>
                            <td>9.10</td>
                            <td>3.75</td>
                            <td>1.44</td>
                            <td>19.42</td>
                            <td>17.90</td>
                            <td>11.36</td>
                        </tr>
                        <tr>
                            <td>Claude 3</td>
                            <td>29.21</td>
                            <td>16.22</td>
                            <td>9.17</td>
                            <td>4.40</td>
                            <td>22.85</td>
                            <td>31.58</td>
                            <td>21.78</td>
                        </tr>
                        <tr>
                            <td>GPT-4 Turbo</td>
                            <td>28.23</td>
                            <td>13.72</td>
                            <td>6.26</td>
                            <td>2.82</td>
                            <td>21.61</td>
                            <td>28.47</td>
                            <td>16.41</td>
                        </tr>
                    </table>
                </div>
            </div>
        </div>
    </div>
</section>




<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
