<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Embodied Agent in Urban Environment">
  <meta name="keywords" content="Embodied, Embodied,Benchmark, Agent, GPT-4V">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Embodied Agent in Urban Environment</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=??"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', '???');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>



<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">EMBODIEDCITY</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">

<!--                <span class="author-block">-->
<!--                  <span>Author : </span>-->
<!--              </span>-->
<!--              <a href="https://fi.ee.tsinghua.edu.cn/~gaochen/">Chen Gao et al.</a><sup>*</sup>-->
<!--              </span>-->

<!--          </div>-->

<!--          <div class="is-size-5 publication-authors">-->
<!--            <span class="author-block">Tsinghua University&nbsp;&nbsp;</span>-->
<!--            <span class="author-block">&nbsp;Beijing, China</span>-->
<!--          </div>-->

<!--           <div class="is-size-5 publication-authors">-->
<!--                <span class="author-block"><sup>*</sup> Equal contribution </span>-->
<!--                <span class="author-block"><sup>&sect;</sup> Corresponding authors</span>-->
<!--           </div>-->
                <div class="column has-text-centered">
                    <div class="publication-links">
                <span class="link-block">
                <a href="./static/article/EmbodiedCity.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Article</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
Embodied artificial intelligence (EmbodiedAI) emphasizes the role of an agentâ€™s
body in generating human-like behaviors. The recent efforts on EmbodiedAI pay
a lot of attention to building up machine learning models to possess perceiving,
planning, and acting abilities, thereby enabling real-time interaction with the world.
However, most works focus on bounded indoor environments, such as navigation
in a room or manipulating a device, with limited exploration of embodying the
agents in open-world scenarios. That is, embodied intelligence in the open and
outdoor environment is less explored, for which one potential reason is the lack
of high-quality simulators, benchmarks, and datasets. To address it, in this paper,
we construct a benchmark platform for embodied intelligence evaluation in real-
world city environments. Specifically, we first construct a highly realistic 3D
simulation environment based on the real buildings, roads, and other elements
in a real city. In this environment, we combine historically collected data and
simulation algorithms to conduct simulations of pedestrian and vehicle flows with
high fidelity. Further, we designed a set of evaluation tasks covering different
EmbodiedAI abilities. Moreover, we provide a complete set of input and output
interfaces for access, enabling embodied agents to easily take task requirements and
current environmental observations as input and then make decisions and obtain
performance evaluations. On the one hand, it expands the capability of existing
embodied intelligence to higher levels. On the other hand, it has a higher practical
value in the real world and can support more potential applications for artificial
general intelligence. Based on this platform, we evaluate some popular large
language models for embodied intelligence capabilities of different dimensions and
difficulties. The executable program of this platform is available for download, and
we have also released an easy-to-use Python library and detailed tutorial documents.
All of the software, Python library, codes, datasets, tutorials, and real-time online
service are available on this anonymous website: <a href="https://embodied-ai.
city">https://embodied-ai.
city</a>.
          </p>

        </div>
      </div>
    </div>
</section>


<section class="section">
    <div class="container is-max-desktop">
        <div class="columns is-centered">
            <div class="column is-full-width">


                    <br></br>
                <h3 class="title is-4" >Author</h3>
                <p>
                    Chen Gao
, Baining Zhao
, Weichen Zhang, Jinzhu Mao, Jun Zhang, Zhiheng Zheng,
Fanhang Man, Jianjie Fang, Zile Zhou, Jinqiang Cui,
Xinlei Chen, Yong Li
                    <br></br>
                </p>
                    <h3 class="title is-4" >Introduction</h3>
                    <div class="content has-text-justified">

                    <p>
                        We first constructed a city-embodied environment simulator. This platform is developed based on a city simulator, providing 3D environments and interactions. The basic environment of the simulator includes a large business district in Beijing, one of the biggest city in China, in which we build 3D model for buildings, streets, and other elements, hosted by Unreal Engine 4.17. We further build the interface of embodied agents to ensure the agents can indeed embod themselves in the system. To implement it,we use the AirSim plugin provide by Microsoft. Specifically, AirSim is originally designed for airdrones, for which the observations are conducted through a first-view manner, and the control for airdrones includes motion, velocity, accelerated velocity, etc.
                    </p>

                    <h3 class="title is-5" style="text-align: center;">Benchmark Framework</h3>
                    <img src="./static/images/figure1.jpg" alt="Figure 1" style="width: 80%; height: auto; display: block; margin: 0 auto;">

                    <h3 class="title is-5" style="text-align: center;">Overview of Simulator</h3>
                    <img src="./static/images/simulator.jpg"/>

                    <p>
                       We defined a system of five tasks, including embodied scene description, embodied question answering, embodied dialogue, embodied visual language navigation, and embodied task planning. For each task, we carefully and manually set up the input/output, and construct the ground truth data combined with large language models and human labor. We also provide the interface for the platform through which the agents can obtain the embodied observations and take actions in real-time simulation, after which the agent can be evaluated. Moreover, we deploy the most famous and widely used large language models to construct the embodied agents, the intelligence level of which is evaluated on five tasks.
                    </p>

                    <h3 class="title is-5" style="text-align: center;">Embodied Tasks</h3>
                    <img src="./static/images/benchmark.jpg"/>
    </div>
</section>


<section class="section">
    <div class="container is-max-desktop">
        <div class="columns is-centered">
            <div class="column is-full-width">
                <h3 class="title is-4" >Result</h3>
                <div class="content has-text-justified">

                    <br><br>
                    <table>
                        <p>Table 1 :Results of embodied first-view scene understanding, including typical evaluation metrics: BLEU, ROUGE, METEOR, and CIDEr.</p>
                        <tr>
                            <th>Model</th>
                            <th>BLEU-1</th>
                            <th>BLEU-2</th>
                            <th>BLEU-3</th>
                            <th>BLEU-4</th>
                            <th>ROUGE</th>
                            <th>METEOR</th>
                            <th>CIDEr</th>
                        </tr>
                        <tr>
                            <td>fuyu-8B</td>
                            <td>40.25</td>
                            <td>20.26</td>
                            <td>8.40</td>
                            <td>1.57</td>
                            <td>17.29</td>
                            <td>15.80</td>
                            <td>21.55</td>
                        </tr>
                        <tr>
                            <td>Qwen-VL</td>
                            <td>40.57</td>
                            <td>17.59</td>
                            <td>5.90</td>
                            <td>0.98</td>
                            <td>14.61</td>
                            <td>19.13</td>
                            <td>18.40</td>
                        </tr>
                        <tr>
                            <td>Claude 3</td>
                            <td>57.38</td>
                            <td>31.73</td>
                            <td>16.83</td>
                            <td>7.19</td>
                            <td>21.60</td>
                            <td>29.00</td>
                            <td>29.20</td>
                        </tr>
                        <tr>
                            <td>GPT-4 Turbo</td>
                            <td>54.01</td>
                            <td>27.63</td>
                            <td>12.73</td>
                            <td>4.53</td>
                            <td>21.99</td>
                            <td>28.48</td>
                            <td>22.39</td>
                        </tr>
                    </table>

                    <br><br>
                    <table>
                        <p>Table 2 :Results of embodied question answering. The Counting task involves querying the number
                            of a specific object within the field of view. The Property task entails inquiring about the attributes of
                            spatial entities such as city buildings or objects within the field of view, including aspects like shape
                            and color. The Position task concerns querying the spatial relationships between different urban
                            elements within the field of view.
                        </p>

                        <tr>
                            <th>Type</th>
                            <th>Model</th>
                            <th>BLEU-1</th>
                            <th>BLEU-2</th>
                            <th>BLEU-3</th>
                            <th>BLEU-4</th>
                            <th>ROUGE</th>
                            <th>METEOR</th>
                            <th>CIDEr</th>
                        </tr>
                        <tr>
                            <td rowspan="4">Counting</td>
                            <td>fuyu-8B</td>
                            <td>12.00</td>
                            <td>7.15</td>
                            <td>1.07</td>
                            <td>0.40</td>
                            <td>16.45</td>
                            <td>15.41</td>
                            <td>8.87</td>
                        </tr>
                        <tr>
                            <td>Qwen-VL</td>
                            <td>5.49</td>
                            <td>1.19</td>
                            <td>0.10</td>
                            <td>0.00</td>
                            <td>11.46</td>
                            <td>17.89</td>
                            <td>3.58</td>
                        </tr>
                        <tr>
                            <td>Claude 3</td>
                            <td>6.08</td>
                            <td>4.33</td>
                            <td>2.79</td>
                            <td>2.13</td>
                            <td>10.54</td>
                            <td>16.82</td>
                            <td>7.95</td>
                        </tr>
                        <tr>
                            <td>GPT-4 Turbo</td>
                            <td>12.84</td>
                            <td>8.81</td>
                            <td>4.33</td>
                            <td>2.78</td>
                            <td>19.26</td>
                            <td>20.18</td>
                            <td>11.56</td>
                        </tr>
                        <tr>
                            <td rowspan="4">Property</td>
                            <td>fuyu-8B</td>
                            <td>20.19</td>
                            <td>18.36</td>
                            <td>16.39</td>
                            <td>14.64</td>
                            <td>31.55</td>
                            <td>20.34</td>
                            <td>22.56</td>
                        </tr>
                        <tr>
                            <td>Qwen-VL</td>
                            <td>55.77</td>
                            <td>48.43</td>
                            <td>40.90</td>
                            <td>31.94</td>
                            <td>65.33</td>
                            <td>61.73</td>
                            <td>33.30</td>
                        </tr>
                        <tr>
                            <td>Claude 3</td>
                            <td>49.34</td>
                            <td>41.88</td>
                            <td>34.10</td>
                            <td>23.44</td>
                            <td>60.51</td>
                            <td>55.29</td>
                            <td>29.84</td>
                        </tr>
                        <tr>
                            <td>GPT-4 Turbo</td>
                            <td>76.63</td>
                            <td>72.17</td>
                            <td>68.57</td>
                            <td>65.51</td>
                            <td>80.16</td>
                            <td>77.10</td>
                            <td>61.44</td>
                        </tr>
                        <tr>
                            <td rowspan="4">Position</td>
                            <td>fuyu-8B</td>
                            <td>7.46</td>
                            <td>0.15</td>
                            <td>0.00</td>
                            <td>0.00</td>
                            <td>18.94</td>
                            <td>4.40</td>
                            <td>12.86</td>
                        </tr>
                        <tr>
                            <td>Qwen-VL</td>
                            <td>7.88</td>
                            <td>4.63</td>
                            <td>3.81</td>
                            <td>0.83</td>
                            <td>18.03</td>
                            <td>22.00</td>
                            <td>16.62</td>
                        </tr>
                        <tr>
                            <td>Claude 3</td>
                            <td>7.57</td>
                            <td>5.85</td>
                            <td>4.37</td>
                            <td>1.56</td>
                            <td>19.04</td>
                            <td>34.28</td>
                            <td>18.82</td>
                        </tr>
                        <tr>
                            <td>GPT-4 Turbo</td>
                            <td>64.54</td>
                            <td>61.85</td>
                            <td>59.44</td>
                            <td>55.31</td>
                            <td>70.72</td>
                            <td>68.87</td>
                            <td>58.45</td>
                        </tr>
                    </table>



                    <br><br>
                    <table>
                        <caption>Table 3 :Results of embodied dialogue.</caption>
                        <tr>
                            <th>Model</th>
                            <th>BLEU-1</th>
                            <th>BLEU-2</th>
                            <th>BLEU-3</th>
                            <th>BLEU-4</th>
                            <th>ROUGE</th>
                            <th>METEOR</th>
                            <th>CIDEr</th>
                        </tr>
                        <tr>
                            <td>fuyu-8B</td>
                            <td>29.05</td>
                            <td>16.73</td>
                            <td>8.24</td>
                            <td>4.30</td>
                            <td>28.53</td>
                            <td>30.12</td>
                            <td>14.47</td>
                        </tr>
                        <tr>
                            <td>Qwen-VL</td>
                            <td>17.91</td>
                            <td>9.54</td>
                            <td>3.90</td>
                            <td>2.03</td>
                            <td>19.33</td>
                            <td>19.65</td>
                            <td>10.30</td>
                        </tr>
                        <tr>
                            <td>Claude 3</td>
                            <td>24.86</td>
                            <td>18.02</td>
                            <td>13.14</td>
                            <td>9.70</td>
                            <td>29.06</td>
                            <td>38.56</td>
                            <td>28.62</td>
                        </tr>
                        <tr>
                            <td>GPT-4 Turbo</td>
                            <td>41.77</td>
                            <td>34.27</td>
                            <td>27.82</td>
                            <td>23.26</td>
                            <td>42.29</td>
                            <td>51.72</td>
                            <td>35.64</td>
                        </tr>
                    </table>


                    <br><br>
                    <table>
                      <caption>Table 4: Results of embodied vision-and-language navigation.</caption>
                      <thead>
                         <tr>
                          <th rowspan="2" style="vertical-align: middle; text-align: center;">Model</th>
                          <th colspan="3" style="vertical-align: middle; text-align: center;">Short</th>
                          <th colspan="3" style="vertical-align: middle; text-align: center;">Long</th>
                          <th colspan="3" style="vertical-align: middle; text-align: center;">Mean</th>
                        </tr>
                        <tr>
                          <th>SR/%</th>
                          <th>SPL/%</th>
                          <th>NE/m</th>
                          <th>SR/%</th>
                          <th>SPL/%</th>
                          <th>NE/m</th>
                          <th>SR/%</th>
                          <th>SPL/%</th>
                          <th>NE/m</th>
                        </tr>
                      </thead>
                      <tbody>
                        <tr>
                          <td>Qwen-VL</td>
                          <td>33.33</td>
                          <td>29.60</td>
                          <td>67.30</td>
                          <td>8.33</td>
                          <td>6.67</td>
                          <td>145.3</td>
                          <td>22.22</td>
                          <td>19.33</td>
                          <td>120.44</td>
                        </tr>
                        <tr>
                          <td>Claude 3</td>
                          <td>76.92</td>
                          <td>75.60</td>
                          <td>139.11</td>
                          <td>20.00</td>
                          <td>19.65</td>
                          <td>185.48</td>
                          <td>34.90</td>
                          <td>34.25</td>
                          <td>162.35</td>
                        </tr>
                        <tr>
                          <td>GPT-4 Turbo</td>
                          <td>60.90</td>
                          <td>55.21</td>
                          <td>95.93</td>
                          <td>15.62</td>
                          <td>14.16</td>
                          <td>127.87</td>
                          <td>27.71</td>
                          <td>25.12</td>
                          <td>111.92</td>
                        </tr>
                        <tr>
                          <td>GPT-4O</td>
                          <td>76.92</td>
                          <td>75.60</td>
                          <td>77.23</td>
                          <td>20.00</td>
                          <td>19.65</td>
                          <td>102.98</td>
                          <td>34.90</td>
                          <td>34.25</td>
                          <td>90.11</td>
                        </tr>
                      </tbody>
                    </table>

                    <br><br>
                    <table>
                        <caption>Table 5 :Results of embodied task planning.</caption>
                        <tr>
                            <th>Model</th>
                            <th>BLEU-1</th>
                            <th>BLEU-2</th>
                            <th>BLEU-3</th>
                            <th>BLEU-4</th>
                            <th>ROUGE</th>
                            <th>METEOR</th>
                            <th>CIDEr</th>
                        </tr>
                        <tr>
                            <td>fuyu-8B</td>
                            <td>15.11</td>
                            <td>6.37</td>
                            <td>1.71</td>
                            <td>0.45</td>
                            <td>14.72</td>
                            <td>19.11</td>
                            <td>16.84</td>
                        </tr>
                        <tr>
                            <td>Qwen-VL</td>
                            <td>20.28</td>
                            <td>9.10</td>
                            <td>3.75</td>
                            <td>1.44</td>
                            <td>19.42</td>
                            <td>17.90</td>
                            <td>11.36</td>
                        </tr>
                        <tr>
                            <td>Claude 3</td>
                            <td>29.21</td>
                            <td>16.22</td>
                            <td>9.17</td>
                            <td>4.40</td>
                            <td>22.85</td>
                            <td>31.58</td>
                            <td>21.78</td>
                        </tr>
                        <tr>
                            <td>GPT-4 Turbo</td>
                            <td>28.23</td>
                            <td>13.72</td>
                            <td>6.26</td>
                            <td>2.82</td>
                            <td>21.61</td>
                            <td>28.47</td>
                            <td>16.41</td>
                        </tr>
                    </table>
                </div>
            </div>
        </div>
    </div>
</section>




<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
